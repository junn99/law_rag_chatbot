{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "law_rag_eval\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# # !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"law_rag_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jun/my_project/Law_RAG_PJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jun/my_project/Law_RAG_PJ/rag_eval\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[init_pinecone_index]\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'law-pdf-hypersearch_rag': {'vector_count': 2139}},\n",
      " 'total_vector_count': 2139}\n"
     ]
    }
   ],
   "source": [
    "from law_rag import PINECONERAG\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# CHROMARAG 객체 생성\n",
    "rag = PINECONERAG(ChatGroq(model=\"gemma2-9b-it\",temperature=0), # gemma2-9b-it(평가용) , llama-3.2-11b-text-preview(연습용)\n",
    ")\n",
    "\n",
    "# 검색기(retriever) 생성\n",
    "retriever = rag.create_retriever()\n",
    "\n",
    "# 체인(chain) 생성\n",
    "chain = rag.create_chain(retriever)\n",
    "\n",
    "# 질문에 대한 답변 생성\n",
    "# chain.invoke(\"임차권등기명령은 어떻게 해?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain.invoke(inputs[\"question\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.kiwi_tokenizer import KiwiTokenizer\n",
    "\n",
    "# 토크나이저 선언\n",
    "kiwi_tokenizer = KiwiTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jun/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "wn.ensure_loaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate import meteor_score\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "\n",
    "# 토크나이저 병렬화 설정(HuggingFace 모델 사용)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "\n",
    "def rouge_evaluator(metric: str = \"rouge2\") -> dict: # rouge1, rouge2, rougeL로 바꿀 수 있음\n",
    "    # wrapper function 정의\n",
    "    def _rouge_evaluator(run: Run, example: Example) -> dict:\n",
    "        # 출력값과 정답 가져오기\n",
    "        student_answer = run.outputs.get(\"answer\", \"\")\n",
    "        reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "        # ROUGE 점수 계산\n",
    "        scorer = rouge_scorer.RougeScorer(\n",
    "            [\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True, tokenizer=KiwiTokenizer()\n",
    "        )\n",
    "        scores = scorer.score(reference_answer, student_answer)\n",
    "\n",
    "        # ROUGE 점수 반환\n",
    "        rouge = scores[metric].fmeasure\n",
    "\n",
    "        return {\"key\": \"ROUGE\", \"score\": rouge}\n",
    "\n",
    "    return _rouge_evaluator\n",
    "\n",
    "\n",
    "def bleu_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # 토큰화\n",
    "    reference_tokens = kiwi_tokenizer.tokenize(reference_answer, type=\"sentence\")\n",
    "    student_tokens = kiwi_tokenizer.tokenize(student_answer, type=\"sentence\")\n",
    "\n",
    "    # BLEU 점수 계산\n",
    "    bleu_score = sentence_bleu([reference_tokens], student_tokens)\n",
    "\n",
    "    return {\"key\": \"BLEU\", \"score\": bleu_score}\n",
    "\n",
    "\n",
    "def meteor_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # 토큰화\n",
    "    reference_tokens = kiwi_tokenizer.tokenize(reference_answer, type=\"list\")\n",
    "    student_tokens = kiwi_tokenizer.tokenize(student_answer, type=\"list\")\n",
    "\n",
    "    # METEOR 점수 계산\n",
    "    meteor = meteor_score.meteor_score([reference_tokens], student_tokens)\n",
    "\n",
    "    return {\"key\": \"METEOR\", \"score\": meteor}\n",
    "\n",
    "\n",
    "def semscore_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # SentenceTransformer 모델 로드\n",
    "    model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "    # 문장 임베딩 생성\n",
    "    student_embedding = model.encode(student_answer, convert_to_tensor=True)\n",
    "    reference_embedding = model.encode(reference_answer, convert_to_tensor=True)\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    cosine_similarity = util.pytorch_cos_sim(\n",
    "        student_embedding, reference_embedding\n",
    "    ).item()\n",
    "\n",
    "    return {\"key\": \"sem_score\", \"score\": cosine_similarity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Heuristic-EVAL-pinecone-ensembleretriever-7:3 + reranking-60ad3d18' at:\n",
      "https://smith.langchain.com/o/8fb13a5d-db0a-55ac-abc3-9ac5cc1b15ae/datasets/dec0eb44-d1f3-4cdf-aeea-6283fc0b7175/compare?selectedSessions=1e40055a-9496-4951-a6bd-0167b2f87479\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51904f18eb79474db3b0e5e472a128fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jun/.conda/envs/chromagroq/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 평가자 정의\n",
    "heuristic_evalulators = [\n",
    "    rouge_evaluator(metric=\"rouge2\"),\n",
    "    # bleu_evaluator,\n",
    "    # meteor_evaluator,\n",
    "    semscore_evaluator,\n",
    "]\n",
    "\n",
    "# 데이터셋 이름 설정\n",
    "dataset_name = \"Law_RAG_Eval_Dataset\"\n",
    "\n",
    "# 실험 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=heuristic_evalulators,\n",
    "    experiment_prefix=\"Heuristic-EVAL-pinecone-ensembleretriever-7:3 + reranking\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Heuristic-EVAL (Rouge, SemScore) 을 사용하여 평가\",\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chromagroq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
